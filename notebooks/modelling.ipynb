{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78434704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e600c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/02_processed/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eba46c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19607065, 19)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b9a8ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'pickup_datetime_dayofyear', 'pickup_datetime_month',\n",
       "       'pickup_datetime_year', 'pickup_datetime_hour',\n",
       "       'pickup_datetime_dayofweek', 'pickup_datetime_is_weekend',\n",
       "       'is_late_night', 'is_night', 'is_early_morning', 'is_rush_hour',\n",
       "       'trip_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dae582de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.960706e+07\n",
       "mean     1.293649e+01\n",
       "std      1.076349e+01\n",
       "min      1.000000e-02\n",
       "25%      7.000000e+00\n",
       "50%      9.500000e+00\n",
       "75%      1.450000e+01\n",
       "max      9.520000e+02\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38b9eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a443de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_sin'] = np.sin(2 * np.pi * df['pickup_datetime_hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['pickup_datetime_hour'] / 24)\n",
    "\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['pickup_datetime_dayofweek'] / 7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['pickup_datetime_dayofweek'] / 7)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['pickup_datetime_month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['pickup_datetime_month'] / 12)\n",
    "\n",
    "df['doy_sin'] = np.sin(2 * np.pi * df['pickup_datetime_dayofyear'] / 366)\n",
    "df['doy_cos'] = np.cos(2 * np.pi * df['pickup_datetime_dayofyear'] / 366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d5ab135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['pickup_datetime_hour', 'pickup_datetime_dayofweek', \n",
    "         'pickup_datetime_month', 'pickup_datetime_dayofyear'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c1a88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['pickup_longitude', 'pickup_latitude',\n",
    "                    'dropoff_longitude', 'dropoff_latitude', 'trip_distance',\n",
    "                    'passenger_count', 'pickup_datetime_year']\n",
    "\n",
    "bool_features = ['pickup_datetime_is_weekend', 'is_late_night', 'is_night',\n",
    "                 'is_early_morning', 'is_rush_hour']\n",
    "\n",
    "cyclic_features = ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos',\n",
    "                   'month_sin', 'month_cos', 'doy_sin', 'doy_cos']\n",
    "\n",
    "all_features = numeric_features + bool_features + cyclic_features\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('passthrough_bool', 'passthrough', bool_features),\n",
    "        ('passthrough_cyclic', 'passthrough', cyclic_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9242e93",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 299. MiB for an array with shape (2, 19607065) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m     vif_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [variance_inflation_factor(X_with_const\u001b[38;5;241m.\u001b[39mvalues, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]  \u001b[38;5;66;03m# skip constant\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vif_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     18\u001b[0m vif_df \u001b[38;5;241m=\u001b[39m calculate_vif(X)\n",
      "File \u001b[1;32mc:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6815\u001b[0m     )\n",
      "File \u001b[1;32mc:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32mc:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 299. MiB for an array with shape (2, 19607065) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "def calculate_vif(X):\n",
    "    # Add a constant column for intercept\n",
    "    X_with_const = add_constant(X)\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i + 1)\n",
    "                       for i in range(X.shape[1])]  # skip constant\n",
    "    return vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "\n",
    "X = df.copy()\n",
    "# Example usage:\n",
    "vif_df = calculate_vif(X)\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295a108",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0f279ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15685652, 20), (3921413, 20), (15685652,), (3921413,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['fare_amount'])\n",
    "y = df['fare_amount']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 17.40546718430118\n",
      "\n",
      "Root Mean Squared Error: 4.1719860000126054\n",
      "\n",
      "Coeficient: [ 2.26031292e-01  2.99751251e-01 -3.74515856e-01 -4.61654390e-01\n",
      "  9.97457126e+00  4.89317849e-02  1.90787257e-01 -2.90791419e-01\n",
      "  3.24696157e-01  3.12050995e-01 -4.67046989e-01  6.56319153e-02\n",
      " -3.71826314e-01 -1.12939213e+00  1.34094081e-01 -2.57087724e-01\n",
      "  1.18521725e-01 -1.09759603e-01 -2.74179352e-01 -1.20594265e-03]\n",
      "\n",
      "Intercept: 12.823490951831921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\MY_FILES\\Learning\\Practice\\04_KAGGLE_NYC_TFP\\nyc_tfp\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "version = \"v4\"\n",
    "with mlflow.start_run(run_name=f\"LinearRegression_{version}\"):\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Mean Squared Error: {mse}\\n\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\\n\")\n",
    "    print(f\"Coeficient: {model.coef_}\\n\")\n",
    "    print(f\"Intercept: {model.intercept_}\\n\")\n",
    "\n",
    "    # Log parameters (no hyperparams in LinearRegression, but log fit_intercept etc.)\n",
    "    mlflow.log_param(\"features\", \", \".join(X_train.columns))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    coefs = pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"coefficient\": model.coef_\n",
    "    })\n",
    "    coefs_file = f\"feature_importance_{version}.csv\"\n",
    "    coefs.to_csv(coefs_file, index=False)\n",
    "    mlflow.log_artifact(coefs_file)\n",
    "\n",
    "    # Log model\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    # Optionally provide an example input (for documentation/UI)\n",
    "    input_example = X_train.iloc[:5]\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nyc-taxi-fp-py3.12)",
   "language": "python",
   "name": "nyc-taxi-fp-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
